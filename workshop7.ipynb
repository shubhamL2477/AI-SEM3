{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUyscnzt1Pm4sbe9NMxdYj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamL2477/AI-SEM3/blob/main/workshop7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCOxISYtq_aP",
        "outputId": "a99f6fd6-b4af-4f2d-ac35-99438368d74b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Test MSE: 5059656033.13\n",
            "Best Ridge alpha: 10\n",
            "Best Lasso alpha: 10\n",
            "Zero coefficients: 0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1. Load dataset\n",
        "X, y = fetch_openml(\n",
        "    name=\"california_housing\",\n",
        "    version=1,\n",
        "    as_frame=True,\n",
        "    return_X_y=True,\n",
        "    parser=\"pandas\" # Ensures consistent dataframe handling\n",
        ")\n",
        "\n",
        "# 2. Preprocessing\n",
        "# Remove categorical feature as you intended\n",
        "X = X.drop(columns=[\"ocean_proximity\"])\n",
        "\n",
        "# 3. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --- HELPER: Pipeline Factory ---\n",
        "# Ridge and Lasso are sensitive to the scale of features.\n",
        "# We use a Pipeline to handle Imputation + Scaling + Model in one go.\n",
        "def create_pipeline(model):\n",
        "    return Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')), # Fixes the NaN issue\n",
        "        ('scaler', StandardScaler()),                 # Scales data for regularization\n",
        "        ('regressor', model)\n",
        "    ])\n",
        "\n",
        "# 4. Baseline Linear Regression\n",
        "lr_pipe = create_pipeline(LinearRegression())\n",
        "lr_pipe.fit(X_train, y_train)\n",
        "print(f\"Baseline Test MSE: {mean_squared_error(y_test, lr_pipe.predict(X_test)):.2f}\")\n",
        "\n",
        "# 5. Ridge with Cross-Validation\n",
        "ridge_pipe = create_pipeline(Ridge())\n",
        "# Note the prefix 'regressor__' to target the model inside the pipeline\n",
        "ridge_cv = GridSearchCV(\n",
        "    ridge_pipe,\n",
        "    {'regressor__alpha': [0.1, 1, 10, 100]},\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error'\n",
        ")\n",
        "ridge_cv.fit(X_train, y_train)\n",
        "print(f\"Best Ridge alpha: {ridge_cv.best_params_['regressor__alpha']}\")\n",
        "\n",
        "# 6. Lasso with Cross-Validation\n",
        "lasso_pipe = create_pipeline(Lasso(max_iter=10000))\n",
        "lasso_cv = GridSearchCV(\n",
        "    lasso_pipe,\n",
        "    {'regressor__alpha': [0.1, 1, 10, 100]},\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error'\n",
        ")\n",
        "lasso_cv.fit(X_train, y_train)\n",
        "\n",
        "best_lasso = lasso_cv.best_estimator_.named_steps['regressor']\n",
        "print(f\"Best Lasso alpha: {lasso_cv.best_params_['regressor__alpha']}\")\n",
        "print(f\"Zero coefficients: {np.sum(best_lasso.coef_ == 0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1. Load data\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --- HELPER: Pipeline Factory ---\n",
        "def create_log_pipeline(penalty='l2', solver='lbfgs', C=1.0):\n",
        "    return Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('classifier', LogisticRegression(penalty=penalty, solver=solver, C=C, max_iter=10000))\n",
        "    ])\n",
        "\n",
        "# 2. Baseline Logistic Regression (No Penalty)\n",
        "log_reg = create_log_pipeline(penalty=None)\n",
        "log_reg.fit(X_train, y_train)\n",
        "print(f\"Baseline Accuracy: {accuracy_score(y_test, log_reg.predict(X_test)):.4f}\")\n",
        "\n",
        "# 3. L1 vs L2 Regularization\n",
        "# 'liblinear' or 'saga' solvers are required for L1\n",
        "log_l1 = create_log_pipeline(penalty='l1', solver='liblinear', C=0.5)\n",
        "log_l2 = create_log_pipeline(penalty='l2', solver='lbfgs', C=0.5)\n",
        "\n",
        "log_l1.fit(X_train, y_train)\n",
        "log_l2.fit(X_train, y_train)\n",
        "\n",
        "print(f\"L1 Accuracy:       {accuracy_score(y_test, log_l1.predict(X_test)):.4f}\")\n",
        "print(f\"L2 Accuracy:       {accuracy_score(y_test, log_l2.predict(X_test)):.4f}\")\n",
        "\n",
        "# 4. Compare Sparsity (Feature Selection)\n",
        "l1_coefs = log_l1.named_steps['classifier'].coef_\n",
        "l2_coefs = log_l2.named_steps['classifier'].coef_\n",
        "\n",
        "print(f\"\\nL1 Zero Coefficients: {np.sum(l1_coefs == 0)} out of {l1_coefs.size}\")\n",
        "print(f\"L2 Zero Coefficients: {np.sum(l2_coefs == 0)} out of {l2_coefs.size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QW0LU_sqraVw",
        "outputId": "718e61c3-d551-4324-e06d-372f85ed3ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy: 0.9386\n",
            "L1 Accuracy:       0.9737\n",
            "L2 Accuracy:       0.9737\n",
            "\n",
            "L1 Zero Coefficients: 15 out of 30\n",
            "L2 Zero Coefficients: 0 out of 30\n"
          ]
        }
      ]
    }
  ]
}